---
title: "AWS Glueã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³4ã¸ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ã®ã‚¨ãƒ©ãƒ¼å¯¾å‡¦"
emoji: "ğŸ’£"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["aws", "glue", "pyspark"]
published: true
publication_name: "iret"
---

# ã‚¨ãƒ©ãƒ¼å†…å®¹
https://docs.aws.amazon.com/glue/latest/dg/glue-version-support-policy.html

æ—¢å­˜ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³2ã®Glueã‚¸ãƒ§ãƒ–ãŒ2024å¹´1æœˆæœ«ã§ã‚µãƒãƒ¼ãƒˆçµ‚äº†ã«ãªã‚‹ã®ã§ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã¨ã“ã‚è¦‹æ…£ã‚Œãªã„ã‚¨ãƒ©ãƒ¼ã§å¤±æ•—ã—ã¦ã—ã¾ã£ãŸã€‚

```
An error occurred while calling o165.save. File already exists:s3://my-bucket/data/part-00051-50c0f3a2-eba1-521b-1b0a-c6652c129376-a000.csv
```

CSVã®æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼ã£ã½ã„ãŒã€CloudWatch Logsã‚’è¦‹ã‚‹ã¨å‰æ®µã§åˆ¥ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚

```
23/12/13 15:41:51 ERROR Utils: Aborting task
org.apache.spark.SparkUpgradeException: You may get a different result due to the upgrading to Spark >= 3.0:  Fail to format it to '2019-11-29 00:00:00' in the new formatter. You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid datetime string.        
	at org.apache.spark.sql.errors.QueryExecutionErrors$.failToFormatDateTimeInNewFormatterError(QueryExecutionErrors.scala:1076) ~[spark-catalyst_2.12-3.3.0-amzn-1.jar:3.3.0-amzn-1]
ä»¥ä¸‹ç•¥
```

# å¯¾å‡¦

CSVå‡ºåŠ›æ™‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šã§ã“ã®ã‚ˆã†ã«ï¼ˆ`.option("dateFormat", "yyyy-MM-dd HH:mm:ss")`ï¼‰æ—¥ä»˜ã®æ›¸å¼è¨­å®šã—ã¦ã„ãŸã‚¸ãƒ§ãƒ–ã ã‘ãŒã‚¨ãƒ©ãƒ¼ã«ãªã£ã¦ã„ãŸã€‚
ã‚¨ãƒ©ãƒ¼æ–‡ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«3.0ä»¥é™ã¯ã“ã®æ›¸å¼ãŒãã®ã¾ã¾ã§ã¯ä½¿ãˆãªã„ã‚ˆã†ãªã®ã§ã€ä¸‹è¨˜ã®ã‚ˆã†ã«å¤ã„ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã“ã¨ã§è§£æ¶ˆã•ã‚ŒãŸã€‚

```python
spark.conf.set("spark.sql.legacy.timeParserPolicy", "LEGACY")
```

# å‚è€ƒ

https://stackoverflow.com/questions/62602720/string-to-date-migration-from-spark-2-0-to-3-0-gives-fail-to-recognize-eee-mmm
